from pyspark.sql import functions as F

# Assuming df is your DataFrame
# Find the max reporting_date
max_date = df.agg(F.max("reporting_date")).collect()[0][0]

# Filter records for the max reporting_date
filtered_df = df.filter(df["reporting_date"] == max_date)

# Find the max timestamp for the filtered records
max_timestamp = filtered_df.agg(F.max("timestamp")).collect()[0][0]

# Filter records for the max timestamp
final_filtered_df = filtered_df.filter(filtered_df["timestamp"] == max_timestamp)

final_filtered_df.show()